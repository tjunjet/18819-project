{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Exoplanet training data\n",
    "\n",
    "The exoplanet training data has already been separated into X_train, X_test, y_train, y_test. \n",
    "\n",
    "We will use it for the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2000, 37)\n",
      "X_test shape: (2000, 37)\n",
      "Y_train shape: (2000,)\n",
      "Y_test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.loadtxt('middle_data/X_train.txt', delimiter=' ')\n",
    "X_test  = np.loadtxt('middle_data/X_test.txt', delimiter=' ')\n",
    "\n",
    "Y_train = np.loadtxt('middle_data/Y_train.txt', delimiter=' ')\n",
    "Y_test  = np.loadtxt('middle_data/Y_test.txt', delimiter=' ')\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data pre-processing \n",
    "\n",
    "In this step, we will perform normalization of the X dataset, and label y in binary terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape after selection: (2000, 2)\n",
      "X_test shape after selection: (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# Normalize data to the range [-1, 1] (use the training set to fit the scaler)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Ensure labels are binary (if not already binary)\n",
    "Y_train = (Y_train > np.median(Y_train)).astype(int)\n",
    "Y_test = (Y_test > np.median(Y_test)).astype(int)\n",
    "\n",
    "print(f\"X_train shape after selection: {X_train.shape}\")\n",
    "print(f\"X_test shape after selection: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building dataset \n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating MLP Model\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 512)\n",
    "        self.linear2 = nn.Linear(512, 512)\n",
    "        self.linear3 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Training Loop\n",
    "# Referenced from: https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "def train_one_epoch(model, criterion, optimizer, trainloader):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in tqdm(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    return train_loss\n",
    "\n",
    "def evaluate_loss(model, criterion, testloader, device):\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "    avg_loss = test_loss / len(testloader)\n",
    "    return avg_loss\n",
    "\n",
    "def evaluate_accuracy(model, testloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy\n",
    "\n",
    "def train(model, optimizer, criterion, trainloader, testloader, epochs, device):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(torch.device(device))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'EPOCH {epoch+1}/{epochs}:', end=\" \")\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_loss = train_one_epoch(model, criterion, optimizer, trainloader)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"Train Loss: {train_loss}\")\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        train_accuracy = evaluate_accuracy(model, trainloader, device)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        print(f\"Test Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "        test_loss = evaluate_loss(model, criterion, testloader, device)\n",
    "        test_losses.append(test_loss)\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "        test_accuracy = evaluate_accuracy(model, testloader, device)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "        # Save best model\n",
    "        if test_loss < best_loss:\n",
    "          best_loss = test_loss\n",
    "          model_path = 'mlp_model_{}'.format(epoch)\n",
    "          torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    return train_losses, test_losses, train_accuracies, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training MLP Model\n",
    "mlp_model = MLPModel(input_size, num_classes)\n",
    "\n",
    "# Print the model architecture\n",
    "print(mlp_model)\n",
    "\n",
    "# Define optimizers for the models\n",
    "optimizer = torch.optim.SGD(mlp_model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Train the NLP model\n",
    "train_losses, test_losses, train_accuracies, test_accuracies = train(mlp_model, optimizer, criterion, trainloader, testloader, epochs, device)\n",
    "torch.save(mlp_model.state_dict(), 'mlp_model_final_weights.pth')\n",
    "torch.save((train_losses, test_losses), 'mlp_model_final_losses.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating MLP Model\n",
    "## Plot loss graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_losses, label=\"Train\")\n",
    "plt.plot(test_losses, label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(f\"MLP Model - Train and Test Losses\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot accuracy graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_accuracies, label=\"Train\")\n",
    "plt.plot(test_accuracies, label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(f\"MLP Model - Train and Test Accuracies\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braket",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
